### Step 1: Install Java (Elasticsearch dependency)
Elasticsearch requires Java, so the first step is to install OpenJDK.

1. Update your package index:
   ```bash
   sudo apt update && sudo apt upgrade
   ```

2. Install OpenJDK:
   ```bash
   sudo apt install openjdk-11-jdk
   ```

3. Verify the installation:
   ```bash
   java -version
   ```

### Step 2: Install and Configure Elasticsearch
[Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/8.11/deb.html) is a highly scalable search and analytics engine.

1. Import the Elasticsearch public GPG key into APT:
   ```bash
   wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
   ```

2. Installing from the APT repository. 
You may need to install the apt-transport-https package on Debian before proceeding:

   ```bash
   sudo apt-get install apt-transport-https

   ```

   Save the repository definition to /etc/apt/sources.list.d/elastic-8.x.list:

   ```markdown
   echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
   ```


3. Update your package index and install Elasticsearch:
   ```bash
   sudo apt-get update && sudo apt-get install elasticsearch
   ```

   Note: save the generated password for the elastic built-in superuser

4. Edit the Elasticsearch configuration file (`/etc/elasticsearch/elasticsearch.yml`). You may use `nano` or your preferred text editor:
   ```bash
   sudo nano /etc/elasticsearch/elasticsearch.yml
   ```
   
   Update the following values:
   ```yaml
    cluster.name:your preferered name
     network.host: 0.0.0.0
     http.port: 9200
   ```

5. Start and enable Elasticsearch:
   ```bash
	sudo /bin/systemctl daemon-reload
   ```
   
   ```bash
	sudo /bin/systemctl enable elasticsearch.service
   ```

   ```bash
	sudo systemctl start elasticsearch.service
	```
   
   ```bash
   sudo systemctl stop elasticsearch.service
   ```


### Step 3: Install and Configure Kibana
Kibana lets you visualize your Elasticsearch data and navigate the Elastic Stack.

1. Install Kibana and Logstash:
   ```bash
   sudo apt-get install kibana logstash
   ```

2. Generate enrollment token for Kibana
   ```
   cd /usr/share/elasticsearch/bin/
   ```
	```
   sudo ./elasticsearch-create-enrollment-token -s kibana
   ```
	
   Note: save the generated enrollment token

2. Edit the Kibana configuration file (`/etc/kibana/kibana.yml`):
   ```bash
   sudo nano /etc/kibana/kibana.yml
   ```
   Update the following values:
   ```yaml
   server.port: 5601
   server.host: "0.0.0.0"
   elasticsearch.hosts: ["http://localhost:9200"]
   ```

3. Start and enable Kibana:
   ```bash
	sudo /bin/systemctl daemon-reload
	```
   ```bash
   sudo /bin/systemctl enable kibana.service
   ```

   ```bash
	sudo systemctl start kibana.service
   ```
   ```bash
	sudo systemctl status kibana.service
   ```
   ```bash
   sudo systemctl stop kibana.service
   ```

### Step 4: Configure Logstash
Logstash is a server-side data processing pipeline that ingests data from multiple sources simultaneously.

1. Start and enable Logstash:
   ```bash
   sudo systemctl enable logstash
   ```

   ```bash
   sudo systemctl start logstash
   ```
   ```bash
   sudo systemctl status logstash
   ```

### Step 5: Accessing Kibana
- Once all components are set up, access Kibana by navigating to `http://your_server_ip:5601` in your web browser.
- On first instance of accessing kibana you will be required to enter the generated enrollment token for kibana
- You will also be asked to provide the verification code
```
cd /usr/share/kibana/bin/
```
```
sudo ./kibana-verification-code
```

**Current Status**: 
- Successfully installed Snort (Intrusion Detection System), Elasticsearch (Search and Analytics Engine), Kibana (Data Visualization Dashboard), and Logstash (Data Processing Pipeline) across our virtual machine (VM) setup.
- However, as of now, there is no data flow from Snort to Elasticsearch via Logstash, which means Kibana does not display any data yet.

**Architecture Overview**:
- We have divided our setup across two separate VMs:
  - **VM1**: Hosts Snort and FileBeat.
  - **VM2**: Hosts Logstash, Elasticsearch, and Kibana.

**Next Steps for Integration**:
- **FileBeat Installation and Configuration on VM1**:
  - We need to install FileBeat on VM1, where Snort is running. FileBeat will act as a log shipper.
  - Its role will be to forward Snort logs to Logstash on VM2 efficiently.
  - After installing FileBeat, it must be configured to read log files generated by Snort and send them to Logstash.

**Finalizing the Data Flow Path**:
- The complete data flow will be as follows: **Snort (VM1) -> FileBeat (VM1) -> Logstash (VM2) -> Elasticsearch (VM2) -> Kibana (VM2)**.
- This setup ensures efficient log management and real-time data analysis and visualization through the ELK Stack.

### Additional Notes
- **Firewall Settings**: If you have a firewall enabled, ensure that the necessary ports are open (especially 5601 for Kibana).
- **Elasticsearch Memory**: If your machine has less RAM, you might need to configure Elasticsearch to use less memory.
- **Security Considerations**: This guide assumes a local setup. For production environments, consider implementing additional security measures, such as securing communication with SSL/TLS and setting up user authentication.
